@name colossus
#[
"Colossus" is the catchy name for an automated integrated combat system of systems in garry's mod. Plainly, it's an evil self-aware artificial intelligence that controls drones, with mission to wipe out everything else but itself and claim the whole map as it's kingdom. Those who will know what movie this is a wink to, major kudos.

It consits of a central "expert system" that acts like an artificial intelligence; transforming raw data into clear information. It then looks for the appropriate course of action to take and then translates this into an order, wich is transmitted down the chain of command to the right unit. A wide range of possibilities exist for integration of new actions; such as building new units, re-wiring stuff and ecetera. 

And what the hell is an Expert System? Wiki tells us that "In artificial intelligence, an expert system is a computer system that emulates the decision-making ability of a human expert. Expert systems are designed to solve complex problems by reasoning about knowledge, like an expert, and not by following the procedure of a developer as is the case in conventional programming." It does not exactly start from scratch or need live training; it has all it's knowledge and rule bases in software that can be edited out of game. 

Why an expert system? Why the extra complication?
People are smart. Very smart. People come up with a lot of ways to overcome limited freedom of actions. However an expert system has the ability to reason further, still as far as it's code, but it's code gives the opportunity to process information in a way to use deductive reasonning to create new information, describing the input ones. It will not be able to ask itself 'To be or not to be' but it is going to be able to tell apart two people watching youtube videos or coding from one guy in a plane coming straight at it. 

This is also an experiment in autonomous systems and artificial intelligence. The biggest hurdle in AI is the learning time. Our knowledge and grasp of our enviromnent, as humans, is acquired over years of growing up, education and experience; tightly supervised. But before that there is the experience and knowledge of the entire history of mankind, the useful bits compiled and taught to you. So a newly created AI is starting from scratch; it is not even at the level of an unicellular organism that has instinctly knows how to regulate it's functions. This is why i beleive that unless we Standardize our algorithms and AI's so that all knowledge can be shared; or that we feed it with a pre-coded knowledge base; useful neural-net based AI is not possible.

It is a synergy of many of my ideas. gISTAR (Intelligence, Surveillance, Targetting, Acquisition and Recon) is a sensor network that fuses the information from up to 64 sensors into a single table. gC3 (Command, Control, Coordination) aka Skynet 001-002 is an experiment at having a central automated machine assign orders to units automatically by radio; and also a command-chain experiment in thought. gISTAR was tested up to the second tier (4*4 nodes) and Skynet002 to the first tier (4).  Of course, this project would begin at a similar level before moving on to depeer levels of integration.

One thing that sets it apart from a normal computer is Natural Language Programming. This means using structured phrases as instructions, in plain (if somewhat robotic) english. An Ontology enables us to be extremely precise about things we are describing; and with some creative coding this translates into a phenomenally versatile data storage and search system.

This comes from the gBrain thread, forget who posted it but kudos
[quote]
ONTOLOGY
An ontology is divided into several domains (groups):

Instances - Any individual thing that actually exists. Sort of like "object" as 
opposed to "class".
Ex:  Apple, Tree, Car...

Classes - All kinds of things. Categories of things and their common properties.
Ex: A Car is a Vehicle, a Vehicle is a Machine

Attributes - Properties that anything can have.
Ex: Machines are inanimate, mechanical objects

Relations - Things like "bigger" "smaller" "inside" and "is a part of".
Ex: Engine is part of Car

Restrictions - Describes what is possible and what is not.
Ex: Car with no Engine is not Vehicle

Rules - Usually a lot of "if-else" statements.
Ex: Socrates is a Man. All Men are Mortal. Therefore Socrates is Mortal

Axioms - All of the logically expressible "theory" that the AI refers to.
Ex: if A>B, A is larger than B

Events - History of changes in relations and attributes of objects.
Ex: Socrates is Dead

Function terms - "shorthand notation" of something complex that can be used to 
refer to it instead.
[/quote]

The natural language algorithm uses these to describe, interpret and draw decisions from the world. Other words are used to simply describe concepts such as NPC=LIVING THING, wich allows it to draw distinctions and use this information in the decision-making process. It can put together a situation with an 'importance level' from applying axioms to several instances sharing common classes and attributes. What this simply means is that it can at least make decisions on the level of ['he is shooting at me'+'player'+'i am taking damage'='i am under attack by player X']

One thing wich bothers me is the mix of hardware and software required. Perhaps it is best to begin with a hard-wired, inflexible design to have a working model before moving on to a software-controlled level. 

The Central Core is inspired by the gBrain but it uses other methods than genetic algorithms for decision-making. It uses keywords, heuristics and a relational database in deductive reasoning ([url=http://en.wikipedia.org/wiki/Deductive_reasoning]link[/url]) to fuse information. This leaves out learning, but learning is such a complex subject that it is best to leave it to when this system is not just on paper. The information it can receive consists of lists of acquired targets (see the gISTAR project) and information relating to the units it controls. Specific conditions and keywords bring it to a precise course of action.

It is similar to the gBrain whitout the genetics. It is more an 'expert system' than AI as said. It consists of Cognition and Information Fusing , Pattern Finding and Correlation and finally Decision Making and Planning. These parts do not require intercommunication hence a simple pipeline can be implemented for speeding up the process. New information that may be "realised" during the thought process and required to be fed into the system is added to the top of the information stack. On the bottom of the core is the "Out" stack, wich is a list of strings that consists of orders and the 'network address' of their recipient. An E2 radio/communication system sends these orders one after the other until the stack is empty. Inbound packets are sent to the "In" stack. Communications are standardized, as are orders to the utter limit. Orders are very much mission-oriented by saying 'go there, do this' instead of micromanaging and remote-controlling everything the system leaves the individual units to perform the mission with it's code that uses these standardized inputs.

Now i will describe the basic components of the system.

=====

THE CORE

IN STACK
This is a table where new information is appended in by the various inputs and popped out by the CIFSYS. This ensures that no information is lost due to lag.

COGNITION AND INFORMATION FUSING SYSTEM - CIFSYS - "Cognition"
It's cognition uses sensor data and things we can find out in expression2 to search a knowledge database; to precisely determine what it is sensing. This cognition operates at a very high tickrate, having to process large amounts of information quickly. This is the part where it will take what it's multiple sensors see and go through an extensive if-then routine to precisely narrow down what we are dealing with. Once it knows what it's looking at; it defines it with a unique name and adjectives describing it. These adjectives are used for referencing by the next stag
